{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uut4CBZMCqOh"
      },
      "source": [
        "# Final Exam Assignment (40 points - Total of 45 is Possible)\n",
        "## Due December 7, 2022, @ 8:00 am\n",
        "Note that there will be no extensions given for this assignment as there is a tight timeline for grading. \n",
        "\n",
        "For this assignment, I have provided each of you with your own training dataset. Your goal is to train a deep neural network to uncover the code image provided to you. \n",
        "\n",
        "I will provide you with instructions throughout. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "siMiNR67CqOo"
      },
      "outputs": [],
      "source": [
        "# Add your import statements here\n",
        "import os\n",
        "import numpy as np\n",
        "import urllib\n",
        "import time\n",
        "import sys\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "skip-execution"
        ],
        "id": "ydvrsEtTCqOq"
      },
      "outputs": [],
      "source": [
        "# This is a tool I have provided you to help you download your file.\n",
        "\n",
        "def download_file(url, filename):\n",
        "    \"\"\"\n",
        "    A function that downloads the data file from a URL\n",
        "    Parameters\n",
        "    ----------\n",
        "    url : string\n",
        "        url where the file to download is located\n",
        "    filename : string\n",
        "        location where to save the file\n",
        "    reporthook : function\n",
        "        callback to display the download progress\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(filename):\n",
        "        urllib.request.urlretrieve(url, filename, reporthook)\n",
        "        \n",
        "def reporthook(count, block_size, total_size):\n",
        "    \"\"\"\n",
        "    A function that displays the status and speed of the download\n",
        "    \"\"\"\n",
        "\n",
        "    global start_time\n",
        "    if count == 0:\n",
        "        start_time = time.time()\n",
        "        return\n",
        "    duration = time.time() - start_time\n",
        "    progress_size = int(count * block_size)\n",
        "    speed = int(progress_size / (1024 * duration + 0.0001))\n",
        "    percent = int(count * block_size * 100 / total_size)\n",
        "    sys.stdout.write(\"\\r...%d%%, %d MB, %d KB/s, %d seconds passed\" %\n",
        "                     (percent, progress_size / (1024 * 1024), speed, duration))\n",
        "    sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "skip-execution"
        ],
        "id": "VjdyWeDnCqOr"
      },
      "outputs": [],
      "source": [
        "# You can download your file by typing your first name into the name block\n",
        "# The name used is the first part of your first name as listed in BB learn\n",
        "# If you have problems downloading the data please reach out to me\n",
        "\n",
        "name = 'Lauren'\n",
        "download_file(f'https://zenodo.org/record/7339649/files/data_{name}.npz?download=1','data.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXWvENmMCqOr"
      },
      "source": [
        "## Loading the Data (3 points)\n",
        "The data is provided to you as a compressed NumPy array saved as 'data.npz'. When working with real data you might need to figure out how data is stored. Use the information on 'npz' files to figure out what data you have. The data file contains three NumPy arrays. \n",
        "1. The features for the training dataset\n",
        "2. The regression values for the training dataset\n",
        "3. The validation features that contain your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5sbNxYGtCqOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5fc3bb8-fcd6-4386-ab7e-3d8b44bc8732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features:  (100000, 30)\n",
            "Regression Values:  (100000, 3)\n",
            "Validation Features:  (65536, 30)\n"
          ]
        }
      ],
      "source": [
        "with np.load('data.npz', allow_pickle=True) as data:\n",
        "    training_feat = data['training_feat']   #features for training dataset\n",
        "    training_true = data['training_true']   #regression values for training dataset\n",
        "    validation_feat = data['validation_feat'] #validation features that contain your code\n",
        "\n",
        "#check sizes\n",
        "print(\"Training Features: \", training_feat.shape)\n",
        "print(\"Regression Values: \", training_true.shape)\n",
        "print(\"Validation Features: \", validation_feat.shape)     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UExFzmBSCqOt"
      },
      "source": [
        "## Preprocessing the Data (5 points)\n",
        "\n",
        "You should explore the data and figure out the best way to preprocess the data. \n",
        "\n",
        "Hints: \n",
        "1. For the regression values, these at the end will represent colors in RGB space from [0,1]. It is recommended to use a max-min scalar between 0 and 1. \n",
        "2. For the training features, you should look at the data and determine the best scaling method. Look at our class notes for a reminder of what other scaler might be useful. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r2RVPch_CqOv"
      },
      "outputs": [],
      "source": [
        "#Regression Values, min-max scalar\n",
        "mm_scaler = MinMaxScaler()\n",
        "scaled_training_true = mm_scaler.fit_transform(training_true)   \n",
        "\n",
        "#Training features, standard scaler\n",
        "s_scaler =  StandardScaler()\n",
        "scaled_training_feat = s_scaler.fit_transform(training_feat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQkXGOPiCqOv"
      },
      "source": [
        "## Building the Dataset (5 points)\n",
        "\n",
        "When training neural networks it is important to build a dataset that allows the machinery to sample the data. This also can be used to conduct some preprocessing of the data to make it work with PyTorch. \n",
        "\n",
        "I have provided you with the framework for a Dataset Class. \n",
        "\n",
        "You should:\n",
        "1. Convert the x and y data to a tensor 'float32' and put it on the GPU.\n",
        "2. Save the len of the data\n",
        "3. Add the code so when `__getitem__` is called it returns the x and y values\n",
        "3. make it so `__len__` returns the lenght when calle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [
          "skip-execution"
        ],
        "id": "4SYPdiNlCqOw"
      },
      "outputs": [],
      "source": [
        "class Data(): #TODO: what is Dataset inheritance in the copied code\n",
        "  '''Dataset Class to store the samples and their corresponding labels, \n",
        "  and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
        "  '''\n",
        "\n",
        "  def __init__(self, X: np.ndarray, y: np.ndarray, device = 'cuda') -> None:\n",
        "\n",
        "    # need to convert float64 to float32 else \n",
        "    # will get the following error\n",
        "    # RuntimeError: expected scalar type Double but found Float\n",
        "    self.X = X.astype(np.float32)\n",
        "    self.y = y.astype(np.float32)\n",
        "    self.len = len(self.X)\n",
        "  \n",
        "  def __getitem__(self, index: int) -> tuple:\n",
        "    return self.X[index], self.y[index]\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return self.len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlYs7nmPCqOw"
      },
      "source": [
        "## Train-test Split (3 points)\n",
        "\n",
        "1. You should conduct a train-test split of the training data so you can make sure that your model does not overfit the data. A good ratio is 66/33 train \n",
        "2. You should instantiate the training dataset using the data class implemented above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PBPg5KbGCqOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d892151-da22-4b7a-c8c2-6bb0c0804d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(67000, 30) (67000, 3)\n"
          ]
        }
      ],
      "source": [
        "#Split train/test and put into Data object\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_training_feat, scaled_training_true, test_size = 0.33, random_state = 42)\n",
        "training_data = Data(X_train, y_train)\n",
        "\n",
        "#check results\n",
        "print(training_data.X.shape, training_data.y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu4SIHHUCqOx"
      },
      "source": [
        "## Build the Dataloader (3 points)\n",
        "\n",
        "Pytorch uses DataLoaders to efficiently sample from a training dataset. Instantiate a Pytorch DataLoader using the dataset. \n",
        "\n",
        "You should set the following parameters:\n",
        "1. Batch size = 64\n",
        "2. Shuffle = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P6n1vlLSCqOx"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size = 64, shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G62_UOgGCqOx"
      },
      "source": [
        "## Building a Neural Network (5 points)\n",
        "\n",
        "Using the provided class framework which inherits the `nn.Module` type in PyTorch builds a 4-layer neural network to complete the multiple regression.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": [
          "skip-execution"
        ],
        "id": "8WJzqUHiCqOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14029e61-e3ad-44a7-f51a-e397bcd4f27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "class Neural_Network(nn.Module):\n",
        "  ''' Regression Model\n",
        "  ''' \n",
        "\n",
        "  # note, you can ignore the `:int` and `-> None` this is just more advanced doctring syntax\n",
        "  def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
        "      '''The network has 4 layers\n",
        "            - input layer\n",
        "            - ReLu\n",
        "            - hidden layer\n",
        "            - ReLu\n",
        "            - hidden layer\n",
        "            - ReLu\n",
        "            - output layer\n",
        "      '''\n",
        "      super(Neural_Network, self).__init__()\n",
        "      # in this part you should intantiate each of the layer components\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear_relu_stack = nn.Sequential(\n",
        "          nn.Linear(input_dim, input_dim),  #input\n",
        "          nn.ReLU(),                        #ReLu\n",
        "          nn.Linear(input_dim, hidden_dim), #hidden\n",
        "          nn.ReLU(),                        #ReLu\n",
        "          nn.Linear(hidden_dim, output_dim),#hidden\n",
        "          nn.ReLU(),                        #ReLu\n",
        "          nn.Linear(output_dim, output_dim))#output\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "      # In this part you should build a model that returns the 3 outputs of the regression\n",
        "      x = self.flatten(x)\n",
        "      preds = self.linear_relu_stack(x)\n",
        "      \n",
        "      return preds\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me91Q395CqOy"
      },
      "source": [
        "## Instantiate the Model (3 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [
          "skip-execution"
        ],
        "id": "OjLry29RCqOy"
      },
      "outputs": [],
      "source": [
        "# number of features (len of X cols)\n",
        "input_dim = X_train.shape[1]\n",
        "# number of hidden layers set this to 50\n",
        "hidden_layers = 50\n",
        "# Add the number of output dimensions\n",
        "output_dim = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [
          "skip-execution"
        ],
        "id": "n0FZbo0jCqOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d14339-dfb3-438e-9b8e-8e8df159c25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural_Network(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=30, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=50, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=50, out_features=3, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=3, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# initiate the regression model\n",
        "# make sure to put it on your GPU\n",
        "model = Neural_Network(input_dim, hidden_layers, output_dim).to(device)\n",
        "print(model)\n",
        "\n",
        "# criterion to computes the loss between input and target\n",
        "# Choose a good criteria\n",
        "loss_fn = nn.MSELoss() #for regression tasks\n",
        "# optimizer that will be used to update weights and biases\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-5)\n",
        "# you can choose any optimizer. I would recommend ADAM.\n",
        "# This problem should not be hard to optimize. A good starting learning rate is 3e-5. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82lwXNKdCqOz"
      },
      "source": [
        "## Train the Model (5 points)\n",
        "\n",
        "Training the model is conducted in a number of steps using loops.\n",
        "\n",
        "1. Set up a loop for each epoch\n",
        "2. Set a parameter to save the running loss\n",
        "3. Set up a nested loop that goes through the batches from the DataLoader you built\n",
        "    - I would recommend using enumerate to include the counts in the loop\n",
        "    - The dataloader will return a tuple that is the inputs and the labels\n",
        "4. Conduct the forward propagation of the model\n",
        "    - Give the model the inputs and compute the outputs\n",
        "    - Compute the loss given the criteria. \n",
        "5. Use the zero gradient method to remove the gradients from the optimizer\n",
        "6. Use the backward method to compute the gradients\n",
        "7. Use the step method in the optimizer to take an optimization step\n",
        "8. Compute the running loss by calling the item method and adding it to the running loss for each minibatch\n",
        "9. For each epoch print the epoch and the loss\n",
        "\n",
        "Note: If you find this challenging I would recommend that you look at examples of other pytorch training loops online. This is a very standard workflow. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [
          "skip-execution"
        ],
        "id": "kJLESBbQCqOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e05fae-3a49-482e-fbd9-14f47ac5510e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.447298  [    0/67000]\n",
            "loss: 0.432213  [ 6400/67000]\n",
            "loss: 0.431272  [12800/67000]\n",
            "loss: 0.413097  [19200/67000]\n",
            "loss: 0.396576  [25600/67000]\n",
            "loss: 0.325331  [32000/67000]\n",
            "loss: 0.301421  [38400/67000]\n",
            "loss: 0.247990  [44800/67000]\n",
            "loss: 0.208774  [51200/67000]\n",
            "loss: 0.174292  [57600/67000]\n",
            "loss: 0.141855  [64000/67000]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.163027  [    0/67000]\n",
            "loss: 0.136777  [ 6400/67000]\n",
            "loss: 0.120209  [12800/67000]\n",
            "loss: 0.119445  [19200/67000]\n",
            "loss: 0.102448  [25600/67000]\n",
            "loss: 0.098391  [32000/67000]\n",
            "loss: 0.075514  [38400/67000]\n",
            "loss: 0.080382  [44800/67000]\n",
            "loss: 0.067550  [51200/67000]\n",
            "loss: 0.076050  [57600/67000]\n",
            "loss: 0.055331  [64000/67000]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.060148  [    0/67000]\n",
            "loss: 0.049625  [ 6400/67000]\n",
            "loss: 0.052349  [12800/67000]\n",
            "loss: 0.046635  [19200/67000]\n",
            "loss: 0.042355  [25600/67000]\n",
            "loss: 0.036368  [32000/67000]\n",
            "loss: 0.031922  [38400/67000]\n",
            "loss: 0.032221  [44800/67000]\n",
            "loss: 0.029867  [51200/67000]\n",
            "loss: 0.028011  [57600/67000]\n",
            "loss: 0.025678  [64000/67000]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.026113  [    0/67000]\n",
            "loss: 0.022262  [ 6400/67000]\n",
            "loss: 0.023186  [12800/67000]\n",
            "loss: 0.023251  [19200/67000]\n",
            "loss: 0.020283  [25600/67000]\n",
            "loss: 0.016829  [32000/67000]\n",
            "loss: 0.020946  [38400/67000]\n",
            "loss: 0.022723  [44800/67000]\n",
            "loss: 0.019142  [51200/67000]\n",
            "loss: 0.015813  [57600/67000]\n",
            "loss: 0.016822  [64000/67000]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.022603  [    0/67000]\n",
            "loss: 0.020011  [ 6400/67000]\n",
            "loss: 0.021466  [12800/67000]\n",
            "loss: 0.019958  [19200/67000]\n",
            "loss: 0.016993  [25600/67000]\n",
            "loss: 0.018327  [32000/67000]\n",
            "loss: 0.020783  [38400/67000]\n",
            "loss: 0.016288  [44800/67000]\n",
            "loss: 0.014648  [51200/67000]\n",
            "loss: 0.019549  [57600/67000]\n",
            "loss: 0.015785  [64000/67000]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.019510  [    0/67000]\n",
            "loss: 0.017476  [ 6400/67000]\n",
            "loss: 0.015462  [12800/67000]\n",
            "loss: 0.017264  [19200/67000]\n",
            "loss: 0.014922  [25600/67000]\n",
            "loss: 0.015324  [32000/67000]\n",
            "loss: 0.015126  [38400/67000]\n",
            "loss: 0.018086  [44800/67000]\n",
            "loss: 0.018027  [51200/67000]\n",
            "loss: 0.013128  [57600/67000]\n",
            "loss: 0.015412  [64000/67000]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.015822  [    0/67000]\n",
            "loss: 0.017414  [ 6400/67000]\n",
            "loss: 0.013711  [12800/67000]\n",
            "loss: 0.013677  [19200/67000]\n",
            "loss: 0.014230  [25600/67000]\n",
            "loss: 0.015435  [32000/67000]\n",
            "loss: 0.013774  [38400/67000]\n",
            "loss: 0.015052  [44800/67000]\n",
            "loss: 0.014994  [51200/67000]\n",
            "loss: 0.013582  [57600/67000]\n",
            "loss: 0.014893  [64000/67000]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.011437  [    0/67000]\n",
            "loss: 0.010647  [ 6400/67000]\n",
            "loss: 0.012962  [12800/67000]\n",
            "loss: 0.012983  [19200/67000]\n",
            "loss: 0.012343  [25600/67000]\n",
            "loss: 0.013205  [32000/67000]\n",
            "loss: 0.011889  [38400/67000]\n",
            "loss: 0.012107  [44800/67000]\n",
            "loss: 0.011065  [51200/67000]\n",
            "loss: 0.012498  [57600/67000]\n",
            "loss: 0.012473  [64000/67000]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.012843  [    0/67000]\n",
            "loss: 0.010722  [ 6400/67000]\n",
            "loss: 0.012834  [12800/67000]\n",
            "loss: 0.010783  [19200/67000]\n",
            "loss: 0.011956  [25600/67000]\n",
            "loss: 0.009788  [32000/67000]\n",
            "loss: 0.012040  [38400/67000]\n",
            "loss: 0.010192  [44800/67000]\n",
            "loss: 0.010121  [51200/67000]\n",
            "loss: 0.011218  [57600/67000]\n",
            "loss: 0.010170  [64000/67000]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.010367  [    0/67000]\n",
            "loss: 0.010973  [ 6400/67000]\n",
            "loss: 0.009904  [12800/67000]\n",
            "loss: 0.010195  [19200/67000]\n",
            "loss: 0.011484  [25600/67000]\n",
            "loss: 0.010687  [32000/67000]\n",
            "loss: 0.010027  [38400/67000]\n",
            "loss: 0.010504  [44800/67000]\n",
            "loss: 0.010425  [51200/67000]\n",
            "loss: 0.009184  [57600/67000]\n",
            "loss: 0.008709  [64000/67000]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.010217  [    0/67000]\n",
            "loss: 0.008708  [ 6400/67000]\n",
            "loss: 0.009125  [12800/67000]\n",
            "loss: 0.010219  [19200/67000]\n",
            "loss: 0.011394  [25600/67000]\n",
            "loss: 0.010914  [32000/67000]\n",
            "loss: 0.007826  [38400/67000]\n",
            "loss: 0.009617  [44800/67000]\n",
            "loss: 0.008927  [51200/67000]\n",
            "loss: 0.010195  [57600/67000]\n",
            "loss: 0.010573  [64000/67000]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.007465  [    0/67000]\n",
            "loss: 0.008159  [ 6400/67000]\n",
            "loss: 0.008624  [12800/67000]\n",
            "loss: 0.007823  [19200/67000]\n",
            "loss: 0.010216  [25600/67000]\n",
            "loss: 0.008221  [32000/67000]\n",
            "loss: 0.008941  [38400/67000]\n",
            "loss: 0.008533  [44800/67000]\n",
            "loss: 0.009158  [51200/67000]\n",
            "loss: 0.009035  [57600/67000]\n",
            "loss: 0.010200  [64000/67000]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.008868  [    0/67000]\n",
            "loss: 0.007727  [ 6400/67000]\n",
            "loss: 0.009548  [12800/67000]\n",
            "loss: 0.008340  [19200/67000]\n",
            "loss: 0.008406  [25600/67000]\n",
            "loss: 0.009626  [32000/67000]\n",
            "loss: 0.008101  [38400/67000]\n",
            "loss: 0.008216  [44800/67000]\n",
            "loss: 0.007833  [51200/67000]\n",
            "loss: 0.007744  [57600/67000]\n",
            "loss: 0.008248  [64000/67000]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.007024  [    0/67000]\n",
            "loss: 0.008333  [ 6400/67000]\n",
            "loss: 0.008734  [12800/67000]\n",
            "loss: 0.007429  [19200/67000]\n",
            "loss: 0.008081  [25600/67000]\n",
            "loss: 0.007683  [32000/67000]\n",
            "loss: 0.010196  [38400/67000]\n",
            "loss: 0.007109  [44800/67000]\n",
            "loss: 0.007209  [51200/67000]\n",
            "loss: 0.007298  [57600/67000]\n",
            "loss: 0.007341  [64000/67000]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.008528  [    0/67000]\n",
            "loss: 0.006495  [ 6400/67000]\n",
            "loss: 0.007476  [12800/67000]\n",
            "loss: 0.008376  [19200/67000]\n",
            "loss: 0.007463  [25600/67000]\n",
            "loss: 0.008847  [32000/67000]\n",
            "loss: 0.008703  [38400/67000]\n",
            "loss: 0.007245  [44800/67000]\n",
            "loss: 0.008121  [51200/67000]\n",
            "loss: 0.007630  [57600/67000]\n",
            "loss: 0.006471  [64000/67000]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.007282  [    0/67000]\n",
            "loss: 0.006447  [ 6400/67000]\n",
            "loss: 0.008467  [12800/67000]\n",
            "loss: 0.007162  [19200/67000]\n",
            "loss: 0.006757  [25600/67000]\n",
            "loss: 0.008001  [32000/67000]\n",
            "loss: 0.006264  [38400/67000]\n",
            "loss: 0.006998  [44800/67000]\n",
            "loss: 0.009085  [51200/67000]\n",
            "loss: 0.007788  [57600/67000]\n",
            "loss: 0.008287  [64000/67000]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.006530  [    0/67000]\n",
            "loss: 0.006478  [ 6400/67000]\n",
            "loss: 0.006357  [12800/67000]\n",
            "loss: 0.007786  [19200/67000]\n",
            "loss: 0.008449  [25600/67000]\n",
            "loss: 0.006090  [32000/67000]\n",
            "loss: 0.006850  [38400/67000]\n",
            "loss: 0.006591  [44800/67000]\n",
            "loss: 0.006376  [51200/67000]\n",
            "loss: 0.007638  [57600/67000]\n",
            "loss: 0.007296  [64000/67000]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.008193  [    0/67000]\n",
            "loss: 0.006451  [ 6400/67000]\n",
            "loss: 0.007117  [12800/67000]\n",
            "loss: 0.006540  [19200/67000]\n",
            "loss: 0.007138  [25600/67000]\n",
            "loss: 0.010349  [32000/67000]\n",
            "loss: 0.007697  [38400/67000]\n",
            "loss: 0.007665  [44800/67000]\n",
            "loss: 0.006868  [51200/67000]\n",
            "loss: 0.006874  [57600/67000]\n",
            "loss: 0.007756  [64000/67000]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.008335  [    0/67000]\n",
            "loss: 0.008164  [ 6400/67000]\n",
            "loss: 0.007749  [12800/67000]\n",
            "loss: 0.008307  [19200/67000]\n",
            "loss: 0.005946  [25600/67000]\n",
            "loss: 0.006690  [32000/67000]\n",
            "loss: 0.006276  [38400/67000]\n",
            "loss: 0.007147  [44800/67000]\n",
            "loss: 0.008453  [51200/67000]\n",
            "loss: 0.007616  [57600/67000]\n",
            "loss: 0.005571  [64000/67000]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.005468  [    0/67000]\n",
            "loss: 0.006042  [ 6400/67000]\n",
            "loss: 0.006186  [12800/67000]\n",
            "loss: 0.006062  [19200/67000]\n",
            "loss: 0.006026  [25600/67000]\n",
            "loss: 0.006456  [32000/67000]\n",
            "loss: 0.006166  [38400/67000]\n",
            "loss: 0.005730  [44800/67000]\n",
            "loss: 0.008516  [51200/67000]\n",
            "loss: 0.008226  [57600/67000]\n",
            "loss: 0.006081  [64000/67000]\n"
          ]
        }
      ],
      "source": [
        "# start training\n",
        "epochs = 20 # sets the number of epochs to train 20 should be sufficent.\n",
        "# This should take about 5-10 minutes to train.\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X.cuda())\n",
        "        loss = loss_fn(pred, y.cuda())\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrClvXXGCqOz"
      },
      "source": [
        "## Validate the Model (3 points)\n",
        "\n",
        "Use the test dataset from the train-test split to make sure your model is not overfitting\n",
        "\n",
        "1. You can build a dataloader as you did before, this time with the test data.\n",
        "2. Build a validation loop, which you should use `with torch.no_grad()` to make sure you do not modify the gradients, or weights. This will fix your model. \n",
        "3. Instantiate the loss to be 0.\n",
        "4. Build a similar loop to grab the validation dataset. \n",
        "5. Compute the predictions with the model.\n",
        "6. Compute the loss using your loss criteria.\n",
        "7. Print the final loss determined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZsfVUCp9CqO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e556342b-6a98-4b6f-97b0-abedaa9ec219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Loss:  0.006787427968179533\n"
          ]
        }
      ],
      "source": [
        "test_data = Data(X_test, y_test)\n",
        "test_dataloader = DataLoader(test_data, batch_size = 64, shuffle = True)\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X.cuda())\n",
        "            test_loss += loss_fn(pred, y.cuda()).item()\n",
        "            \n",
        "\n",
        "    test_loss /= num_batches\n",
        "    return test_loss\n",
        "    \n",
        "    \n",
        "for t in range(epochs):\n",
        "    test_loss = test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Final Loss: \", test_loss) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf0LggFoCqO0"
      },
      "source": [
        "<p style=\"color:blue\"> Question: Is your model overfitting or not? How do you know? (3 points) </p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UnyrVvvCqO0"
      },
      "source": [
        "As shown in the results above, the loss of the final epoch of training was calculated to be in the range of ~0.0055 to ~0.0085 depending on the batch. The loss on the final epoch on the test set was ~0.0068. Since the loss of the testing data is not drastically larger than the losses in the training data, overfitting is not occurrring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr_6OnntCqO0"
      },
      "source": [
        "## Crack Your Code (3 points)\n",
        "\n",
        "1. You can build a dataloader as you did before, this time with the validation features to view your code.\n",
        "2. Build a loop, you should use `with torch.no_grad()` to make sure you do not modify the gradients or weights. This will fix your model. \n",
        "3. Compute the predictions of your model. \n",
        "    - Make sure you do all the same preprocess, the data has the same datatype, and is on the same device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "94opWiqdCqO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6e093c-e62f-4bbe-a4ec-98488bace57c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([65536, 3])\n"
          ]
        }
      ],
      "source": [
        "s_scaler =  StandardScaler()\n",
        "scaled_validation_feat = s_scaler.fit_transform(validation_feat).astype(np.float32)\n",
        "validation_dataloader = DataLoader(torch.tensor(scaled_validation_feat))\n",
        "\n",
        "def valid_loop(dataloader, model):\n",
        "  with torch.no_grad():\n",
        "    predictions = model(validation_dataloader.dataset.cuda())\n",
        "  return predictions  \n",
        "\n",
        "for t in range(epochs):\n",
        "  predictions = valid_loop(validation_dataloader, model)\n",
        "\n",
        "#check results\n",
        "print(predictions.size())  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tna_0IyUCqO1"
      },
      "source": [
        "## Reveal Your Code (3 points)\n",
        "\n",
        "Your code is an image. there are (65536, 3) predictions this corresponds to a (256,256,3) RGB image. \n",
        "1. Use the detach() method to remove the gradients from the tensor\n",
        "2. Transfer the tensor back to the 'cpu' if you had it on a GPU\n",
        "3. Reshape the image into a 256,256,3 array. \n",
        "4. Plot your successful result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "deTTerlNCqO1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "30863fb3-b69b-49b4-eea9-205159c21e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0310348400>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "predictions = predictions.detach()\n",
        "predictions = predictions.to(\"cpu\")\n",
        "predictions = predictions.reshape((256, 256, 3))\n",
        "plt.imshow(predictions)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "c475b5beda6d617ffb7b2fcf453fbe132321ffc1e1f96c06cf49356e1e7f42cb"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}